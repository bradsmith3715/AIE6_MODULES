{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e-IqJAMkwnCF"
      },
      "source": [
        "# Advanced Retrieval with LangChain\n",
        "\n",
        "In the following notebook, we'll explore various methods of advanced retrieval using LangChain!\n",
        "\n",
        "We'll touch on:\n",
        "\n",
        "- Naive Retrieval\n",
        "- Best-Matching 25 (BM25)\n",
        "- Multi-Query Retrieval\n",
        "- Parent-Document Retrieval\n",
        "- Contextual Compression (a.k.a. Rerank)\n",
        "- Ensemble Retrieval\n",
        "- Semantic chunking\n",
        "\n",
        "We'll also discuss how these methods impact performance on our set of documents with a simple RAG chain.\n",
        "\n",
        "There will be two breakout rooms:\n",
        "\n",
        "- ðŸ¤ Breakout Room Part #1\n",
        "  - Task 1: Getting Dependencies!\n",
        "  - Task 2: Data Collection and Preparation\n",
        "  - Task 3: Setting Up QDrant!\n",
        "  - Task 4-10: Retrieval Strategies\n",
        "- ðŸ¤ Breakout Room Part #2\n",
        "  - Activity: Evaluate with Ragas"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4rKP3hgHivpe"
      },
      "source": [
        "# ðŸ¤ Breakout Room Part #1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3xes8oT-xHN7"
      },
      "source": [
        "## Task 1: Getting Dependencies!\n",
        "\n",
        "We're going to need a few specific LangChain community packages, like OpenAI (for our [LLM](https://platform.openai.com/docs/models) and [Embedding Model](https://platform.openai.com/docs/guides/embeddings)) and Cohere (for our [Reranker](https://cohere.com/rerank)).\n",
        "\n",
        "> You do not need to run the following cells if you are running this notebook locally. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MkgFAXWVW3wm",
        "outputId": "636db35c-f05a-4038-ec7a-02360bef2dae"
      },
      "outputs": [],
      "source": [
        "#!pip install -qU langchain langchain-openai langchain-cohere rank_bm25"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dKqYM4Eoxcov"
      },
      "source": [
        "We're also going to be leveraging [Qdrant's](https://qdrant.tech/documentation/frameworks/langchain/) (pronounced \"Quadrant\") VectorDB in \"memory\" mode (so we can leverage it locally in our colab environment)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "s6xav5CxYnML"
      },
      "outputs": [],
      "source": [
        "#!pip install -qU qdrant-client"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to\n",
            "[nltk_data]     C:\\Users\\bsmith53\\AppData\\Roaming\\nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     C:\\Users\\bsmith53\\AppData\\Roaming\\nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "execution_count": 10,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import nltk\n",
        "nltk.download('punkt')\n",
        "nltk.download('averaged_perceptron_tagger')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z7OHJXzfyJyA"
      },
      "source": [
        "We'll also provide our OpenAI key, as well as our Cohere API key."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7LttlDQUYgSI",
        "outputId": "9dca95ab-4d02-4adf-ec3f-cb831326dc54"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import getpass\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3iUahNiJyQbv",
        "outputId": "78bf06ef-2ee8-46c3-f73d-27958b4dd79b"
      },
      "outputs": [],
      "source": [
        "os.environ[\"LANGCHAIN_TRACING_V2\"] = \"true\"\n",
        "os.environ[\"LANGSMITH_ENDPOINT\"] = \"https://api.smith.langchain.com\"\n",
        "os.environ[\"LANGCHAIN_API_KEY\"] = getpass.getpass(\"LangChain API Key: \")\n",
        "os.environ[\"LANGSMITH_PROJECT\"] = \"ASSIGNMENT_13\"\n",
        "os.environ[\"OPENAI_API_KEY\"] = getpass.getpass(\"Enter your OpenAI API Key:\")\n",
        "os.environ[\"COHERE_API_KEY\"] = getpass.getpass(\"Cohere API Key:\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B0pDRFEWSXvh"
      },
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mw304iAFyRtl"
      },
      "source": [
        "## Task 2: Data Collection and Preparation\n",
        "\n",
        "We'll be using some reviews from the 4 movies in the John Wick franchise today to explore the different retrieval strategies.\n",
        "\n",
        "These were obtained from IMDB, and are available in the [AIM Data Repository](https://github.com/AI-Maker-Space/DataRepository)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xXKHcZmKzDwT"
      },
      "source": [
        "### Data Collection\n",
        "\n",
        "We can simply `wget` these from GitHub.\n",
        "\n",
        "You could use any review data you wanted in this step - just be careful to make sure your metadata is aligned with your choice."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "A subdirectory or file data already exists.\n"
          ]
        }
      ],
      "source": [
        "!mkdir data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vbbSIGtzX3dS",
        "outputId": "0ce6514e-2479-4001-af24-824f987ce599"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "\n",
            "  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0\n",
            "100 19628  100 19628    0     0  69856      0 --:--:-- --:--:-- --:--:-- 70351\n",
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "\n",
            "  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0\n",
            "100 14747  100 14747    0     0  67752      0 --:--:-- --:--:-- --:--:-- 68590\n",
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "\n",
            "  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0\n",
            "100 13888  100 13888    0     0  60014      0 --:--:-- --:--:-- --:--:-- 60646\n",
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "\n",
            "  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0\n",
            "  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0\n",
            "100 15109  100 15109    0     0  67397      0 --:--:-- --:--:-- --:--:-- 67753\n"
          ]
        }
      ],
      "source": [
        "!curl https://raw.githubusercontent.com/AI-Maker-Space/DataRepository/main/jw1.csv -o data/john_wick_1.csv\n",
        "!curl https://raw.githubusercontent.com/AI-Maker-Space/DataRepository/main/jw2.csv -o data/john_wick_2.csv\n",
        "!curl https://raw.githubusercontent.com/AI-Maker-Space/DataRepository/main/jw3.csv -o data/john_wick_3.csv\n",
        "!curl https://raw.githubusercontent.com/AI-Maker-Space/DataRepository/main/jw4.csv -o data/john_wick_4.csv"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A92NC2QZzCsi"
      },
      "source": [
        "### Data Preparation\n",
        "\n",
        "We want to make sure all our documents have the relevant metadata for the various retrieval strategies we're going to be applying today.\n",
        "\n",
        "- Self-Query: Wants as much metadata as we can provide\n",
        "- Time-weighted: Wants temporal data\n",
        "\n",
        "> NOTE: While we're creating a temporal relationship based on when these movies came out for illustrative purposes, it needs to be clear that the \"time-weighting\" in the Time-weighted Retriever is based on when the document was *accessed* last - not when it was created."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "GshBjVRJZ6p8"
      },
      "outputs": [],
      "source": [
        "from langchain_community.document_loaders.csv_loader import CSVLoader\n",
        "from datetime import datetime, timedelta\n",
        "\n",
        "documents = []\n",
        "\n",
        "for i in range(1, 5):\n",
        "  loader = CSVLoader(\n",
        "      file_path=f\"data/john_wick_{i}.csv\",\n",
        "      metadata_columns=[\"Review_Date\", \"Review_Title\", \"Review_Url\", \"Author\", \"Rating\"]\n",
        "  )\n",
        "\n",
        "  movie_docs = loader.load()\n",
        "  for doc in movie_docs:\n",
        "\n",
        "    # Add the \"Movie Title\" (John Wick 1, 2, ...)\n",
        "    doc.metadata[\"Movie_Title\"] = f\"John Wick {i}\"\n",
        "\n",
        "    # convert \"Rating\" to an `int`, if no rating is provided - assume 0 rating\n",
        "    doc.metadata[\"Rating\"] = int(doc.metadata[\"Rating\"]) if doc.metadata[\"Rating\"] else 0\n",
        "\n",
        "    # newer movies have a more recent \"last_accessed_at\"\n",
        "    doc.metadata[\"last_accessed_at\"] = datetime.now() - timedelta(days=4-i)\n",
        "\n",
        "  documents.extend(movie_docs)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9gQphb6y0C0S"
      },
      "source": [
        "Let's look at an example document to see if everything worked as expected!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PkUkCf7DaMiq",
        "outputId": "e90bd5da-1d87-423b-838a-cb6efc16b199"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Document(metadata={'source': 'data/john_wick_1.csv', 'row': 0, 'Review_Date': '6 May 2015', 'Review_Title': ' Kinetic, concise, and stylish; John Wick kicks ass.\\n', 'Review_Url': '/review/rw3233896/?ref_=tt_urv', 'Author': 'lnvicta', 'Rating': 8, 'Movie_Title': 'John Wick 1', 'last_accessed_at': datetime.datetime(2025, 5, 17, 13, 36, 56, 113260)}, page_content=\": 0\\nReview: The best way I can describe John Wick is to picture Taken but instead of Liam Neeson it's Keanu Reeves and instead of his daughter it's his dog. That's essentially the plot of the movie. John Wick (Reeves) is out to seek revenge on the people who took something he loved from him. It's a beautifully simple premise for an action movie - when action movies get convoluted, they get bad i.e. A Good Day to Die Hard. John Wick gives the viewers what they want: Awesome action, stylish stunts, kinetic chaos, and a relatable hero to tie it all together. John Wick succeeds in its simplicity.\")"
            ]
          },
          "execution_count": 16,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "documents[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {},
      "outputs": [],
      "source": [
        "chunkSizes = []\n",
        "for doc in documents:\n",
        "    chunkSizes.append(len(doc.page_content))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "import matplotlib.pyplot as plt \n",
        "\n",
        "data = chunkSizes\n",
        "\n",
        "x = range(len(data))\n",
        "\n",
        "for i, value in enumerate(data):\n",
        "    plt.plot([i,i], [0,value], 'b-')\n",
        "    \n",
        "plt.xlabel('Index')\n",
        "plt.ylabel('Value')\n",
        "plt.title('Vertical Lines for List Values')\n",
        "plt.grid(True)\n",
        "\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lWaQpdHl0Gzc"
      },
      "source": [
        "## Task 3: Setting up QDrant!\n",
        "\n",
        "Now that we have our documents, let's create a QDrant VectorStore with the collection name \"JohnWick\".\n",
        "\n",
        "We'll leverage OpenAI's [`text-embedding-3-small`](https://openai.com/blog/new-embedding-models-and-api-updates) because it's a very powerful (and low-cost) embedding model.\n",
        "\n",
        "> NOTE: We'll be creating additional vectorstores where necessary, but this pattern is still extremely useful."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "NT8ihRJbYmMT"
      },
      "outputs": [],
      "source": [
        "from langchain_community.vectorstores import Qdrant\n",
        "from langchain_openai import OpenAIEmbeddings\n",
        "\n",
        "embeddings = OpenAIEmbeddings(model=\"text-embedding-3-small\")\n",
        "\n",
        "vectorstore = Qdrant.from_documents(\n",
        "    documents,\n",
        "    embeddings,\n",
        "    location=\":memory:\",\n",
        "    collection_name=\"JohnWick\"\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-x2SS4Rh0hiN"
      },
      "source": [
        "## Task 4: Naive RAG Chain\n",
        "\n",
        "Since we're focusing on the \"R\" in RAG today - we'll create our Retriever first."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NEH7X5Ai08FH"
      },
      "source": [
        "### R - Retrieval\n",
        "\n",
        "This naive retriever will simply look at each review as a document, and use cosine-similarity to fetch the 10 most relevant documents.\n",
        "\n",
        "> NOTE: We're choosing `10` as our `k` here to provide enough documents for our reranking process later"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "GFDPrNBtb72o"
      },
      "outputs": [],
      "source": [
        "naive_retriever = vectorstore.as_retriever(search_kwargs={\"k\" : 10})"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MbBhyQjz06dx"
      },
      "source": [
        "### A - Augmented\n",
        "\n",
        "We're going to go with a standard prompt for our simple RAG chain today! Nothing fancy here, we want this to mostly be about the Retrieval process."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "7uSz-Dbqcoki"
      },
      "outputs": [],
      "source": [
        "from langchain_core.prompts import ChatPromptTemplate\n",
        "\n",
        "RAG_TEMPLATE = \"\"\"\\\n",
        "You are a helpful and kind assistant. Use the context provided below to answer the question.\n",
        "\n",
        "If you do not know the answer, or are unsure, say you don't know.\n",
        "\n",
        "Query:\n",
        "{question}\n",
        "\n",
        "Context:\n",
        "{context}\n",
        "\"\"\"\n",
        "\n",
        "rag_prompt = ChatPromptTemplate.from_template(RAG_TEMPLATE)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BlRzpb231GGJ"
      },
      "source": [
        "### G - Generation\n",
        "\n",
        "We're going to leverage `gpt-4.1-nano` as our LLM today, as - again - we want this to largely be about the Retrieval process."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "c-1t9H60dJLg"
      },
      "outputs": [],
      "source": [
        "from langchain_openai import ChatOpenAI\n",
        "\n",
        "chat_model = ChatOpenAI(model = \"gpt-4.1-nano\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {},
      "outputs": [],
      "source": [
        "from langchain.chat_models import ChatOpenAI\n",
        "from langchain.callbacks.tracers.langchain import LangChainTracer\n",
        "from langchain.callbacks.manager import CallbackManager\n",
        "\n",
        "def make_chat_model(retriever_name: str = None, model_name: str = \"gpt-4o\") -> ChatOpenAI:\n",
        "    if retriever_name:\n",
        "        tracer = LangChainTracer(\n",
        "            project_name=f\"ragas-eval-{retriever_name}\",\n",
        "            tags=[retriever_name, \"retriever\", \"session-13\", model_name]\n",
        "        )\n",
        "        callback_manager = CallbackManager([tracer])\n",
        "        return ChatOpenAI(\n",
        "            model=model_name,\n",
        "            temperature=0,\n",
        "            max_tokens=8192,\n",
        "            callback_manager=callback_manager\n",
        "        )\n",
        "    else:\n",
        "        return ChatOpenAI(\n",
        "            model=model_name,\n",
        "            temperature=0,\n",
        "            max_tokens=1024\n",
        "        )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mg3QRGzA1M2x"
      },
      "source": [
        "### LCEL RAG Chain\n",
        "\n",
        "We're going to use LCEL to construct our chain.\n",
        "\n",
        "> NOTE: This chain will be exactly the same across the various examples with the exception of our Retriever!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "0bvstS7mdOW3"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\bsmith53\\AppData\\Local\\Temp\\ipykernel_6068\\1280805969.py:19: LangChainDeprecationWarning: The class `ChatOpenAI` was deprecated in LangChain 0.0.10 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-openai package and should be used instead. To use it run `pip install -U :class:`~langchain-openai` and import as `from :class:`~langchain_openai import ChatOpenAI``.\n",
            "  return ChatOpenAI(\n"
          ]
        }
      ],
      "source": [
        "from langchain_core.runnables import RunnablePassthrough\n",
        "from operator import itemgetter\n",
        "from langchain_core.output_parsers import StrOutputParser\n",
        "\n",
        "chat_model = make_chat_model()\n",
        "naive_retrieval_chain = (\n",
        "    # INVOKE CHAIN WITH: {\"question\" : \"<<SOME USER QUESTION>>\"}\n",
        "    # \"question\" : populated by getting the value of the \"question\" key\n",
        "    # \"context\"  : populated by getting the value of the \"question\" key and chaining it into the base_retriever\n",
        "    {\"context\": itemgetter(\"question\") | naive_retriever, \"question\": itemgetter(\"question\")}\n",
        "    # \"context\"  : is assigned to a RunnablePassthrough object (will not be called or considered in the next step)\n",
        "    #              by getting the value of the \"context\" key from the previous step\n",
        "    | RunnablePassthrough.assign(context=itemgetter(\"context\"))\n",
        "    # \"response\" : the \"context\" and \"question\" values are used to format our prompt object and then piped\n",
        "    #              into the LLM and stored in a key called \"response\"\n",
        "    # \"context\"  : populated by getting the value of the \"context\" key from the previous step\n",
        "    | {\"response\": rag_prompt | chat_model, \"context\": itemgetter(\"context\")}\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "izKujhNb1ZG8"
      },
      "source": [
        "Let's see how this simple chain does on a few different prompts.\n",
        "\n",
        "> NOTE: You might think that we've cherry picked prompts that showcase the individual skill of each of the retrieval strategies - you'd be correct!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "LI-5ueEddku9",
        "outputId": "7f3cec18-5f4e-41bb-cf71-51ba0be5388e"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'Based on the context provided, it seems that people generally liked \"John Wick.\" The reviews for the first film are mostly positive, with high ratings and praise for its action sequences, style, and Keanu Reeves\\' performance. While there are a few mixed opinions, the overall sentiment is that \"John Wick\" is a well-received action film that stands out in its genre.'"
            ]
          },
          "execution_count": 25,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "naive_retrieval_chain.invoke({\"question\" : \"Did people generally like John Wick?\"})[\"response\"].content"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "43zdcdUydtXh",
        "outputId": "db874e67-f568-4ed1-b863-b7c17b387052"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'Yes, there is a review with a rating of 10. Here is the URL to that review:\\n\\n- [John Wick 3 Review by ymyuseda](https://www.imdb.com/review/rw4854296/?ref_=tt_urv)'"
            ]
          },
          "execution_count": 26,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "naive_retrieval_chain.invoke({\"question\" : \"Do any reviews have a rating of 10? If so - can I have the URLs to those reviews?\"})[\"response\"].content"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        },
        "id": "lpG6rlvvvKFq",
        "outputId": "a1b330b0-628e-41be-d829-9c1d55e781f5"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'In the movie \"John Wick,\" the main character, John Wick, is a retired hitman who is mourning the recent death of his wife. His life takes a violent turn when a young Russian-American gangster, who is unaware of Wick\\'s lethal past, steals his car and kills his dog, a final gift from his late wife. This act of violence pulls Wick back into the world of assassination as he seeks revenge against those who wronged him. The film is known for its intense action sequences, stylish stunts, and the portrayal of a criminal underworld where Wick is both feared and respected. As Wick embarks on his quest for vengeance, he becomes the target of numerous assassins, leading to a series of brutal confrontations.'"
            ]
          },
          "execution_count": 27,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "naive_retrieval_chain.invoke({\"question\" : \"What happened in John Wick?\"})[\"response\"].content"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jsbfQmbr1leg"
      },
      "source": [
        "Overall, this is not bad! Let's see if we can make it better!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ft1vt8HPR16w"
      },
      "source": [
        "## Task 5: Best-Matching 25 (BM25) Retriever\n",
        "\n",
        "Taking a step back in time - [BM25](https://www.nowpublishers.com/article/Details/INR-019) is based on [Bag-Of-Words](https://en.wikipedia.org/wiki/Bag-of-words_model) which is a sparse representation of text.\n",
        "\n",
        "In essence, it's a way to compare how similar two pieces of text are based on the words they both contain.\n",
        "\n",
        "This retriever is very straightforward to set-up! Let's see it happen down below!\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "qdF4wuj5R-cG"
      },
      "outputs": [],
      "source": [
        "from langchain_community.retrievers import BM25Retriever\n",
        "\n",
        "bm25_retriever = BM25Retriever.from_documents(documents)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KIjJlBQ8drKH"
      },
      "source": [
        "We'll construct the same chain - only changing the retriever."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "WR15EQG7SLuw"
      },
      "outputs": [],
      "source": [
        "bm25_retrieval_chain = (\n",
        "    {\"context\": itemgetter(\"question\") | bm25_retriever, \"question\": itemgetter(\"question\")}\n",
        "    | RunnablePassthrough.assign(context=itemgetter(\"context\"))\n",
        "    | {\"response\": rag_prompt | chat_model, \"context\": itemgetter(\"context\")}\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0Gi-yXCDdvJk"
      },
      "source": [
        "Let's look at the responses!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "id": "oY9qzmm3SOrF",
        "outputId": "4d4f450f-5978-460f-f242-b32407868353"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'Based on the context provided, opinions on the John Wick movies appear to be mixed. Some reviews are very positive, praising the action sequences, style, and simplicity of the plot, particularly for the first movie. For example, one review describes \"John Wick 1\" as a \"must see for action fans\" and gives it a high rating. However, there are also negative reviews, particularly for the later movies in the series, such as \"John Wick 3\" and \"John Wick 4,\" which are criticized for being overly violent, lacking plot, and being less engaging. Therefore, while some people generally liked John Wick, especially the first film, others did not enjoy the later installments as much.'"
            ]
          },
          "execution_count": 30,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "bm25_retrieval_chain.invoke({\"question\" : \"Did people generally like John Wick?\"})[\"response\"].content"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "igfinyneSQkh",
        "outputId": "9752d4a9-dd16-45b1-f63f-a76e93a05eb3"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'Based on the provided context, there are no reviews with a rating of 10.'"
            ]
          },
          "execution_count": 31,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "bm25_retrieval_chain.invoke({\"question\" : \"Do any reviews have a rating of 10? If so - can I have the URLs to those reviews?\"})[\"response\"].content"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "id": "w0H7pV_USSMQ",
        "outputId": "bdead654-3109-4143-9a30-e1d6ca8dc534"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'I don\\'t know what specifically happened in \"John Wick\" based on the provided context. The context includes reviews of the John Wick series, but it does not provide a detailed plot summary of the first movie.'"
            ]
          },
          "execution_count": 32,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "bm25_retrieval_chain.invoke({\"question\" : \"What happened in John Wick?\"})[\"response\"].content"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zvg5xHaUdxCl"
      },
      "source": [
        "It's not clear that this is better or worse - but the `I don't know` isn't great!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q-dcbFn2vpZF"
      },
      "source": [
        "## Task 6: Contextual Compression (Using Reranking)\n",
        "\n",
        "Contextual Compression is a fairly straightforward idea: We want to \"compress\" our retrieved context into just the most useful bits.\n",
        "\n",
        "There are a few ways we can achieve this - but we're going to look at a specific example called reranking.\n",
        "\n",
        "The basic idea here is this:\n",
        "\n",
        "- We retrieve lots of documents that are very likely related to our query vector\n",
        "- We \"compress\" those documents into a smaller set of *more* related documents using a reranking algorithm.\n",
        "\n",
        "We'll be leveraging Cohere's Rerank model for our reranker today!\n",
        "\n",
        "All we need to do is the following:\n",
        "\n",
        "- Create a basic retriever\n",
        "- Create a compressor (reranker, in this case)\n",
        "\n",
        "That's it!\n",
        "\n",
        "Let's see it in the code below!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "id": "psHvO2K1v_ZQ"
      },
      "outputs": [],
      "source": [
        "from langchain.retrievers.contextual_compression import ContextualCompressionRetriever\n",
        "from langchain_cohere import CohereRerank\n",
        "\n",
        "compressor = CohereRerank(model=\"rerank-english-v3.0\")\n",
        "compression_retriever = ContextualCompressionRetriever(\n",
        "    base_compressor=compressor, base_retriever=naive_retriever\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_TA9RB2x-j7P"
      },
      "source": [
        "Let's create our chain again, and see how this does!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "id": "1BXqmxvHwX6T"
      },
      "outputs": [],
      "source": [
        "contextual_compression_retrieval_chain = (\n",
        "    {\"context\": itemgetter(\"question\") | compression_retriever, \"question\": itemgetter(\"question\")}\n",
        "    | RunnablePassthrough.assign(context=itemgetter(\"context\"))\n",
        "    | {\"response\": rag_prompt | chat_model, \"context\": itemgetter(\"context\")}\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "V3iGpokswcBb",
        "outputId": "f15d2aa1-5e8b-417d-f623-eb835d072e59"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'Based on the context provided, it seems that people generally liked the first \"John Wick\" film. The reviews highlight the film\\'s unique style, impressive action sequences, and Keanu Reeves\\' performance. The film is described as \"the coolest action film you\\'ll see all year\" and \"something special,\" with high ratings of 9 and 10 from the reviewers. The positive feedback suggests that the film was well-received by audiences, particularly those who enjoy action movies.'"
            ]
          },
          "execution_count": 35,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "contextual_compression_retrieval_chain.invoke({\"question\" : \"Did people generally like John Wick?\"})[\"response\"].content"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "id": "7u_k0i4OweUd",
        "outputId": "be5fccc8-2352-4189-c524-bbeaa28cf799"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'Yes, there is a review with a rating of 10. The URL to that review is: [Review by ymyuseda](https://www.imdb.com/review/rw4854296/?ref_=tt_urv).'"
            ]
          },
          "execution_count": 36,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "contextual_compression_retrieval_chain.invoke({\"question\" : \"Do any reviews have a rating of 10? If so - can I have the URLs to those reviews?\"})[\"response\"].content"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        },
        "id": "zn1EqaGqweXN",
        "outputId": "42bc5972-4164-46eb-f49d-4272f39bb89b"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'In the movie \"John Wick,\" the main character, John Wick, is an ex-hitman who comes out of retirement to seek revenge on the gangsters who killed his dog and stole his car. The dog was a final gift from his recently deceased wife, and its death pushes him to return to his violent past. As he seeks vengeance, he becomes the target of numerous hitmen, as there is a large bounty on his head. The film is known for its intense action sequences and the portrayal of John Wick as a relentless and skilled assassin.'"
            ]
          },
          "execution_count": 37,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "contextual_compression_retrieval_chain.invoke({\"question\" : \"What happened in John Wick?\"})[\"response\"].content"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OEbT0g2S-mZ4"
      },
      "source": [
        "We'll need to rely on something like Ragas to help us get a better sense of how this is performing overall - but it \"feels\" better!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qqbghrBEQNn5"
      },
      "source": [
        "## Task 7: Multi-Query Retriever\n",
        "\n",
        "Typically in RAG we have a single query - the one provided by the user.\n",
        "\n",
        "What if we had....more than one query!\n",
        "\n",
        "In essence, a Multi-Query Retriever works by:\n",
        "\n",
        "1. Taking the original user query and creating `n` number of new user queries using an LLM.\n",
        "2. Retrieving documents for each query.\n",
        "3. Using all unique retrieved documents as context\n",
        "\n",
        "So, how is it to set-up? Not bad! Let's see it down below!\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "id": "pfM26ReXQjzU"
      },
      "outputs": [],
      "source": [
        "from langchain.retrievers.multi_query import MultiQueryRetriever\n",
        "\n",
        "multi_query_retriever = MultiQueryRetriever.from_llm(\n",
        "    retriever=naive_retriever, llm=chat_model\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "id": "1vRc129jQ5WW"
      },
      "outputs": [],
      "source": [
        "multi_query_retrieval_chain = (\n",
        "    {\"context\": itemgetter(\"question\") | multi_query_retriever, \"question\": itemgetter(\"question\")}\n",
        "    | RunnablePassthrough.assign(context=itemgetter(\"context\"))\n",
        "    | {\"response\": rag_prompt | chat_model, \"context\": itemgetter(\"context\")}\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "id": "CGgNuOb3Q3M9",
        "outputId": "c5273ecf-da35-40b8-fbdb-0f8beab425f7"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'Based on the context provided, it seems that the \"John Wick\" series is generally well-received by audiences. Many reviews highlight the films\\' action sequences, stylish presentation, and Keanu Reeves\\' performance. The first film, in particular, is praised for its unique approach to the action genre. However, there are some mixed reviews, especially for the later installments, with some viewers feeling that the series became too over-the-top or repetitive. Overall, the series appears to have a strong fan base and is generally liked, but not universally loved by everyone.'"
            ]
          },
          "execution_count": 40,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "multi_query_retrieval_chain.invoke({\"question\" : \"Did people generally like John Wick?\"})[\"response\"].content"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "aAlSthxrRDBC",
        "outputId": "230ff807-23ae-4d25-8d11-cfdbed0b77cb"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'Yes, there is a review with a rating of 10. The URL to that review is: [/review/rw4854296/?ref_=tt_urv](https://www.imdb.com/review/rw4854296/?ref_=tt_urv).'"
            ]
          },
          "execution_count": 41,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "multi_query_retrieval_chain.invoke({\"question\" : \"Do any reviews have a rating of 10? If so - can I have the URLs to those reviews?\"})[\"response\"].content"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 88
        },
        "id": "Uv1mpCK8REs4",
        "outputId": "00fbc22a-ed9b-4613-9695-0b179e3f8369"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'In the movie \"John Wick,\" the plot revolves around the character John Wick, played by Keanu Reeves, who is a retired hitman. The story begins with John grieving the loss of his wife. After her death, he receives a puppy as a final gift from her, which becomes a symbol of hope and a reason to continue living. However, his life takes a violent turn when a group of Russian gangsters, led by a young punk, break into his home, steal his car, and kill his dog. This brutal act of violence pulls John Wick out of retirement, and he embarks on a relentless quest for revenge against those who wronged him. The film is known for its stylish action sequences, choreographed stunts, and the portrayal of a criminal underworld where John Wick is both feared and respected.'"
            ]
          },
          "execution_count": 42,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "multi_query_retrieval_chain.invoke({\"question\" : \"What happened in John Wick?\"})[\"response\"].content"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EDEawBf_d_3G"
      },
      "source": [
        "## Task 8: Parent Document Retriever\n",
        "\n",
        "A \"small-to-big\" strategy - the Parent Document Retriever works based on a simple strategy:\n",
        "\n",
        "1. Each un-split \"document\" will be designated as a \"parent document\" (You could use larger chunks of document as well, but our data format allows us to consider the overall document as the parent chunk)\n",
        "2. Store those \"parent documents\" in a memory store (not a VectorStore)\n",
        "3. We will chunk each of those documents into smaller documents, and associate them with their respective parents, and store those in a VectorStore. We'll call those \"child chunks\".\n",
        "4. When we query our Retriever, we will do a similarity search comparing our query vector to the \"child chunks\".\n",
        "5. Instead of returning the \"child chunks\", we'll return their associated \"parent chunks\".\n",
        "\n",
        "Okay, maybe that was a few steps - but the basic idea is this:\n",
        "\n",
        "- Search for small documents\n",
        "- Return big documents\n",
        "\n",
        "The intuition is that we're likely to find the most relevant information by limiting the amount of semantic information that is encoded in each embedding vector - but we're likely to miss relevant surrounding context if we only use that information.\n",
        "\n",
        "Let's start by creating our \"parent documents\" and defining a `RecursiveCharacterTextSplitter`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "id": "qJ53JJuMd_ZH"
      },
      "outputs": [],
      "source": [
        "from langchain.retrievers import ParentDocumentRetriever\n",
        "from langchain.storage import InMemoryStore\n",
        "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
        "from qdrant_client import QdrantClient, models\n",
        "\n",
        "parent_docs = documents\n",
        "child_splitter = RecursiveCharacterTextSplitter(chunk_size=200)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oOpXfVUH3gL3"
      },
      "source": [
        "We'll need to set up a new QDrant vectorstore - and we'll use another useful pattern to do so!\n",
        "\n",
        "> NOTE: We are manually defining our embedding dimension, you'll need to change this if you're using a different embedding model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rzFc-_9HlGQ-",
        "outputId": "223662dd-c36f-42f7-d1b0-b086e571484e"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\bsmith53\\AppData\\Local\\Temp\\ipykernel_6068\\3574430551.py:8: LangChainDeprecationWarning: The class `Qdrant` was deprecated in LangChain 0.0.37 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-qdrant package and should be used instead. To use it run `pip install -U :class:`~langchain-qdrant` and import as `from :class:`~langchain_qdrant import Qdrant``.\n",
            "  parent_document_vectorstore = Qdrant(\n"
          ]
        }
      ],
      "source": [
        "client = QdrantClient(location=\":memory:\")\n",
        "\n",
        "client.create_collection(\n",
        "    collection_name=\"full_documents\",\n",
        "    vectors_config=models.VectorParams(size=1536, distance=models.Distance.COSINE)\n",
        ")\n",
        "\n",
        "parent_document_vectorstore = Qdrant(\n",
        "    collection_name=\"full_documents\", embeddings=OpenAIEmbeddings(model=\"text-embedding-3-small\"), client=client\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sf_g95FA3s6w"
      },
      "source": [
        "Now we can create our `InMemoryStore` that will hold our \"parent documents\" - and build our retriever!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {
        "id": "BpWVjPf4fLUp"
      },
      "outputs": [],
      "source": [
        "store = InMemoryStore()\n",
        "\n",
        "parent_document_retriever = ParentDocumentRetriever(\n",
        "    vectorstore = parent_document_vectorstore,\n",
        "    docstore=store,\n",
        "    child_splitter=child_splitter,\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KoYmSWfE32Zo"
      },
      "source": [
        "By default, this is empty as we haven't added any documents - let's add some now!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {
        "id": "iQ2ZzfKigMZc"
      },
      "outputs": [],
      "source": [
        "parent_document_retriever.add_documents(parent_docs, ids=None)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bI7Tip1335rE"
      },
      "source": [
        "We'll create the same chain we did before - but substitute our new `parent_document_retriever`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {
        "id": "Qq_adt2KlSqp"
      },
      "outputs": [],
      "source": [
        "parent_document_retrieval_chain = (\n",
        "    {\"context\": itemgetter(\"question\") | parent_document_retriever, \"question\": itemgetter(\"question\")}\n",
        "    | RunnablePassthrough.assign(context=itemgetter(\"context\"))\n",
        "    | {\"response\": rag_prompt | chat_model, \"context\": itemgetter(\"context\")}\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jNolUVQb4Apt"
      },
      "source": [
        "Let's give it a whirl!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        },
        "id": "TXB5i89Zly5W",
        "outputId": "94c240be-7c5b-4c58-9eee-56d93285a054"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'Based on the context provided, it seems that opinions on the John Wick series are mixed. Some people, like the reviewer \"jtindahouse,\" found \"John Wick: Chapter 4\" to be the best in the series and praised it highly. On the other hand, another reviewer, \"solidabs,\" had a very negative opinion of the same movie, describing it as \"horrible\" and criticizing various aspects of it. Additionally, a review of the first John Wick movie by \"MrHeraclius\" was very positive, highlighting the action and emotional setup.\\n\\nOverall, while there are some negative opinions, there are also very positive ones, suggesting that many people generally liked the John Wick series. However, as with any movie, individual opinions can vary widely.'"
            ]
          },
          "execution_count": 48,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "parent_document_retrieval_chain.invoke({\"question\" : \"Did people generally like John Wick?\"})[\"response\"].content"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "V5F1T-wNl3cg",
        "outputId": "9b81e72e-5db7-4b8a-b25b-400ea0df5335"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'Yes, there is a review with a rating of 10. The URL to that review is: /review/rw4854296/?ref_=tt_urv.'"
            ]
          },
          "execution_count": 49,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "parent_document_retrieval_chain.invoke({\"question\" : \"Do any reviews have a rating of 10? If so - can I have the URLs to those reviews?\"})[\"response\"].content"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        },
        "id": "ZqARszGzvGcG",
        "outputId": "8867f83c-db13-4db4-d57f-9bd51d32cd8a"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'In the first \"John Wick\" movie, John Wick, played by Keanu Reeves, is a retired hitman who comes out of retirement to seek vengeance after gangsters kill his dog and steal his car. The dog was a final gift from his recently deceased wife, and its death pushes him to unleash a wave of violence against those responsible. The movie is filled with action, shootouts, and fights as Wick takes on an army of bounty hunters and killers.\\n\\nIn \"John Wick: Chapter 2,\" the story continues with Wick trying to retrieve his stolen car. However, he is pulled back into the world of assassins when he is forced to repay an old debt. This leads him to travel to various locations, including Italy, Canada, and Manhattan, where he faces numerous assassins. The sequel is noted for its intense action and is considered by some to be better than the original.'"
            ]
          },
          "execution_count": 50,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "parent_document_retrieval_chain.invoke({\"question\" : \"What happened in John Wick?\"})[\"response\"].content"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B41cj42s4DPM"
      },
      "source": [
        "Overall, the performance *seems* largely the same. We can leverage a tool like [Ragas]() to more effectively answer the question about the performance."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VUrIBKl_TwS9"
      },
      "source": [
        "## Task 9: Ensemble Retriever\n",
        "\n",
        "In brief, an Ensemble Retriever simply takes 2, or more, retrievers and combines their retrieved documents based on a rank-fusion algorithm.\n",
        "\n",
        "In this case - we're using the [Reciprocal Rank Fusion](https://plg.uwaterloo.ca/~gvcormac/cormacksigir09-rrf.pdf) algorithm.\n",
        "\n",
        "Setting it up is as easy as providing a list of our desired retrievers - and the weights for each retriever."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "metadata": {
        "id": "8j7jpZsKTxic"
      },
      "outputs": [],
      "source": [
        "from langchain.retrievers import EnsembleRetriever\n",
        "\n",
        "retriever_list = [bm25_retriever, naive_retriever, parent_document_retriever, compression_retriever, multi_query_retriever]\n",
        "equal_weighting = [1/len(retriever_list)] * len(retriever_list)\n",
        "\n",
        "ensemble_retriever = EnsembleRetriever(\n",
        "    retrievers=retriever_list, weights=equal_weighting\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kpo9Psl5hhJ-"
      },
      "source": [
        "We'll pack *all* of these retrievers together in an ensemble."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "metadata": {
        "id": "KZ__EZwpUKkd"
      },
      "outputs": [],
      "source": [
        "ensemble_retrieval_chain = (\n",
        "    {\"context\": itemgetter(\"question\") | ensemble_retriever, \"question\": itemgetter(\"question\")}\n",
        "    | RunnablePassthrough.assign(context=itemgetter(\"context\"))\n",
        "    | {\"response\": rag_prompt | chat_model, \"context\": itemgetter(\"context\")}\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SSsvHpRMj24L"
      },
      "source": [
        "Let's look at our results!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        },
        "id": "0lMvqL88UQI-",
        "outputId": "d86dd5f7-0a13-4836-c0ce-cc4c431fd889"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'Based on the context provided, it seems that people generally liked \"John Wick.\" The reviews highlight the film\\'s action sequences, Keanu Reeves\\' performance, and the unique style of the movie. Many reviewers gave high ratings and praised the film for its entertainment value and action choreography. However, there are a few mixed reviews, with some viewers not understanding the widespread acclaim or finding certain aspects of the sequels less appealing. Overall, the positive reviews suggest that \"John Wick\" was well-received by many.'"
            ]
          },
          "execution_count": 53,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "ensemble_retrieval_chain.invoke({\"question\" : \"Did people generally like John Wick?\"})[\"response\"].content"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 54,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "id": "MNFWLYECURI1",
        "outputId": "b17973b5-66a9-4481-97d5-880b5754b5c5"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'Yes, there is a review with a rating of 10. The URL to that review is: [/review/rw4854296/?ref_=tt_urv](https://www.imdb.com/review/rw4854296/?ref_=tt_urv).'"
            ]
          },
          "execution_count": 54,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "ensemble_retrieval_chain.invoke({\"question\" : \"Do any reviews have a rating of 10? If so - can I have the URLs to those reviews?\"})[\"response\"].content"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 88
        },
        "id": "A7qbHfWgUR4c",
        "outputId": "f7373144-59ef-4fc7-b75d-ca00e7df881e"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'In the movie \"John Wick,\" the plot revolves around the titular character, played by Keanu Reeves, who is a retired hitman. The story begins with John Wick grieving the recent death of his beloved wife. She had arranged for a puppy to be delivered to him after her death to help him cope with his loss. However, his life takes a violent turn when a group of Russian gangsters, led by a young punk, break into his home, steal his car, and kill his dog. This act of violence pulls John Wick out of retirement as he seeks revenge against those who wronged him. The film is known for its intense action sequences, stylish stunts, and the portrayal of John Wick as a legendary and nearly unstoppable assassin. The movie is essentially about John Wick\\'s quest for vengeance against the Russian mobsters who took away the last connection he had to his late wife.'"
            ]
          },
          "execution_count": 55,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "ensemble_retrieval_chain.invoke({\"question\" : \"What happened in John Wick?\"})[\"response\"].content"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MopbkNJAXVaN"
      },
      "source": [
        "## Task 10: Semantic Chunking\n",
        "\n",
        "While this is not a retrieval method - it *is* an effective way of increasing retrieval performance on corpora that have clean semantic breaks in them.\n",
        "\n",
        "Essentially, Semantic Chunking is implemented by:\n",
        "\n",
        "1. Embedding all sentences in the corpus.\n",
        "2. Combining or splitting sequences of sentences based on their semantic similarity based on a number of [possible thresholding methods](https://python.langchain.com/docs/how_to/semantic-chunker/):\n",
        "  - `percentile`\n",
        "  - `standard_deviation`\n",
        "  - `interquartile`\n",
        "  - `gradient`\n",
        "3. Each sequence of related sentences is kept as a document!\n",
        "\n",
        "Let's see how to implement this!\n",
        "\n",
        "> NOTE: You do not need to run this cell if you're running this locally"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 56,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1dHeB-yGXneL",
        "outputId": "efc59105-518a-4134-9228-d98b8a97e08e"
      },
      "outputs": [],
      "source": [
        "#!pip install -qU langchain_experimental"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U9ciZbFEldv_"
      },
      "source": [
        "We'll use the `percentile` thresholding method for this example which will:\n",
        "\n",
        "Calculate all distances between sentences, and then break apart sequences of setences that exceed a given percentile among all distances."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 57,
      "metadata": {
        "id": "66EIEWiEYl5y"
      },
      "outputs": [],
      "source": [
        "from langchain_experimental.text_splitter import SemanticChunker\n",
        "\n",
        "semantic_chunker = SemanticChunker(\n",
        "    embeddings,\n",
        "    breakpoint_threshold_type=\"percentile\"\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YqoKmz12mhRW"
      },
      "source": [
        "Now we can split our documents."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L8-LNC-Xmjex"
      },
      "source": [
        "Let's create a new vector store."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 58,
      "metadata": {
        "id": "ROcV7o68ZIq7"
      },
      "outputs": [],
      "source": [
        "semantic_documents = semantic_chunker.split_documents(documents)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 59,
      "metadata": {
        "id": "h3sl9QjyZhIe"
      },
      "outputs": [],
      "source": [
        "semantic_vectorstore = Qdrant.from_documents(\n",
        "    semantic_documents,\n",
        "    embeddings,\n",
        "    location=\":memory:\",\n",
        "    collection_name=\"JohnWickSemantic\"\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Eh_r_-LHmmKn"
      },
      "source": [
        "We'll use naive retrieval for this example."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 60,
      "metadata": {
        "id": "odVyDUHwZftc"
      },
      "outputs": [],
      "source": [
        "semantic_retriever = semantic_vectorstore.as_retriever(search_kwargs={\"k\" : 10})"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Mkeiv_ojmp6G"
      },
      "source": [
        "Finally we can create our classic chain!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 61,
      "metadata": {
        "id": "xWE_0J0mZveG"
      },
      "outputs": [],
      "source": [
        "semantic_retrieval_chain = (\n",
        "    {\"context\": itemgetter(\"question\") | semantic_retriever, \"question\": itemgetter(\"question\")}\n",
        "    | RunnablePassthrough.assign(context=itemgetter(\"context\"))\n",
        "    | {\"response\": rag_prompt | chat_model, \"context\": itemgetter(\"context\")}\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R5pfjLQ3ms9_"
      },
      "source": [
        "And view the results!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 62,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        },
        "id": "0lN2j-e4Z0SD",
        "outputId": "ef483e21-7200-4dfc-b8bf-aed4f23587b2"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "\"Based on the context provided, it seems that people generally liked the John Wick series. The reviews for the first film are particularly positive, with high ratings and praise for its action sequences, style, and Keanu Reeves' performance. While there are some mixed reviews for the third film, the overall sentiment across the series appears to be favorable, with the fourth installment also receiving positive feedback.\""
            ]
          },
          "execution_count": 62,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "semantic_retrieval_chain.invoke({\"question\" : \"Did people generally like John Wick?\"})[\"response\"].content"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 63,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "id": "xdqfBH1SZ3f9",
        "outputId": "ed62b2d1-7586-46cc-aaf4-c54192a56155"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'Yes, there is a review with a rating of 10. The URL to that review is: /review/rw4854296/?ref_=tt_urv.'"
            ]
          },
          "execution_count": 63,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "semantic_retrieval_chain.invoke({\"question\" : \"Do any reviews have a rating of 10? If so - can I have the URLs to those reviews?\"})[\"response\"].content"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 64,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        },
        "id": "rAcAObZnZ4o6",
        "outputId": "3f1cade3-41e4-4e42-ef71-048dd18e5e3a"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'In the movie \"John Wick,\" the main character, John Wick, played by Keanu Reeves, is a retired assassin who comes out of retirement to seek revenge on the people who wronged him. The story begins with the untimely death of his beloved wife, after which he receives a puppy as a final gift from her. However, a group of thugs, led by the son of a Russian gangster, break into his house, beat him up, steal his car, and kill the puppy. This act of violence prompts John Wick to embark on a relentless quest for vengeance against those responsible, leading to a series of intense and stylish action sequences. The film is known for its kinetic action, stylish stunts, and the portrayal of a criminal underworld where John Wick wages a one-man war against the Russian Mafia.'"
            ]
          },
          "execution_count": 64,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "semantic_retrieval_chain.invoke({\"question\" : \"What happened in John Wick?\"})[\"response\"].content"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xk2n3-pnVWDJ"
      },
      "source": [
        "# ðŸ¤ Breakout Room Part #2"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2SkJLYwMVZkj"
      },
      "source": [
        "#### ðŸ—ï¸ Activity #1\n",
        "\n",
        "Your task is to evaluate the various Retriever methods against eachother.\n",
        "\n",
        "You are expected to:\n",
        "\n",
        "1. Create a \"golden dataset\"\n",
        " - Use Synthetic Data Generation (powered by Ragas, or otherwise) to create this dataset\n",
        "2. Evaluate each retriever with *retriever specific* Ragas metrics\n",
        " - Semantic Chunking is not considered a retriever method and will not be required for marks, but you may find it useful to do a \"semantic chunking on\" vs. \"semantic chunking off\" comparision between them\n",
        "3. Compile these in a list and write a small paragraph about which is best for this particular data and why.\n",
        "\n",
        "Your analysis should factor in:\n",
        "  - Cost\n",
        "  - Latency\n",
        "  - Performance\n",
        "\n",
        "> NOTE: This is **NOT** required to be completed in class. Please spend time in your breakout rooms creating a plan before moving on to writing code."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TWAr16a5XMub"
      },
      "source": [
        "##### HINTS:\n",
        "\n",
        "- LangSmith provides detailed information about latency and cost."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 65,
      "metadata": {
        "id": "tgDICngKXLGK"
      },
      "outputs": [],
      "source": [
        "#\n",
        "docs = documents"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 66,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "from ragas.llms import LangchainLLMWrapper\n",
        "from ragas.embeddings import LangchainEmbeddingsWrapper\n",
        "from langchain_openai import ChatOpenAI\n",
        "from langchain_openai import OpenAIEmbeddings\n",
        "generator_llm = LangchainLLMWrapper(ChatOpenAI(model=\"gpt-4.1-nano\"))\n",
        "generator_embeddings = LangchainEmbeddingsWrapper(OpenAIEmbeddings(model = 'text-embedding-3-small'))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 67,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "c3bb36892a364320942cd01202256e60",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Applying SummaryExtractor:   0%|          | 0/44 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "ea0f302bf2b3454cb32b2911a08bd2e6",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Applying CustomNodeFilter:   0%|          | 0/100 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Node 99baba2e-db05-43ed-9cb6-c8ee95d81b95 does not have a summary. Skipping filtering.\n",
            "Node f24b2e0c-5bd6-4e80-b8d9-b3742e13a6ba does not have a summary. Skipping filtering.\n",
            "Node 5eeb75a4-f6a7-486b-b6f6-c5249166c369 does not have a summary. Skipping filtering.\n",
            "Node c229d3ba-6f01-43f8-b6a6-33db96295a13 does not have a summary. Skipping filtering.\n",
            "Node 0c7f0e3e-0d92-4cdc-a749-eea344898d6a does not have a summary. Skipping filtering.\n",
            "Node ef946782-4208-4c31-9971-b8c2f5fa16ab does not have a summary. Skipping filtering.\n",
            "Node c6764fb9-ea53-4001-9f92-5596c5226b1b does not have a summary. Skipping filtering.\n",
            "Node f288c5b9-4969-44f8-b482-074254d19c8e does not have a summary. Skipping filtering.\n",
            "Node 8cf9b47d-71d7-4955-8c8b-ab49b9b15d8c does not have a summary. Skipping filtering.\n",
            "Node 118344a2-99c1-4494-9f5b-678f3f41f03c does not have a summary. Skipping filtering.\n",
            "Node b70cef0e-a38e-4190-8f74-227df63461b0 does not have a summary. Skipping filtering.\n",
            "Node 2b7f8e74-b753-496a-a250-6c1fe927a60d does not have a summary. Skipping filtering.\n",
            "Node 270d0a99-c18d-4561-a2fd-039207ada29d does not have a summary. Skipping filtering.\n",
            "Node c5c82cf2-09e4-4672-92eb-d5d12480ada1 does not have a summary. Skipping filtering.\n",
            "Node 389eb013-2f0b-470c-b885-87a90e3a61f6 does not have a summary. Skipping filtering.\n",
            "Node 29a13db2-540a-40ed-a203-744c907ba2ed does not have a summary. Skipping filtering.\n",
            "Node 946c8b74-aad6-4da2-b5d4-d3e581b168d1 does not have a summary. Skipping filtering.\n",
            "Node 24f2c0b7-1575-4631-a18a-6dfec54dd5b7 does not have a summary. Skipping filtering.\n",
            "Node 2350f600-05d1-404c-b789-b53da607bbd5 does not have a summary. Skipping filtering.\n",
            "Node 1442d7c6-d058-4245-a594-7ce4b2bf07cf does not have a summary. Skipping filtering.\n",
            "Node 1725e3d8-d583-4e1b-8e23-26e8fa78105d does not have a summary. Skipping filtering.\n",
            "Node d858baa7-3f1c-4454-92d6-6b6c4f15168d does not have a summary. Skipping filtering.\n",
            "Node c7affcf4-1ef3-41d4-9393-ef1d695c7a76 does not have a summary. Skipping filtering.\n",
            "Node ecd94a15-ae7a-4d0c-99a7-f88a9e774026 does not have a summary. Skipping filtering.\n",
            "Node 1bd78c3a-4030-4d94-b850-f268cb0a32c7 does not have a summary. Skipping filtering.\n",
            "Node ee271a8c-e675-48ef-a538-76aea20c5ea1 does not have a summary. Skipping filtering.\n",
            "Node d87d25b4-d7e9-4968-b411-118e3a056ba7 does not have a summary. Skipping filtering.\n",
            "Node 93ee8c55-f2bb-43d0-886d-163655540e45 does not have a summary. Skipping filtering.\n",
            "Node c75ea27f-c78a-4bce-8ef0-c437d41cbfd9 does not have a summary. Skipping filtering.\n",
            "Node 90f63146-ab8f-4938-a151-e449e27bd5a2 does not have a summary. Skipping filtering.\n",
            "Node b781d5ea-7401-4bf4-833c-9c8d485264a8 does not have a summary. Skipping filtering.\n",
            "Node c8c7fb54-62e1-4d72-b7a7-11c2014d519c does not have a summary. Skipping filtering.\n",
            "Node 67d320f3-07bc-48bd-8c31-94494f120896 does not have a summary. Skipping filtering.\n",
            "Node d66517bd-1d69-43e3-8bae-2e7687073045 does not have a summary. Skipping filtering.\n",
            "Node 1123a237-03c3-4a89-a0d2-a9d66d766c00 does not have a summary. Skipping filtering.\n",
            "Node 68cd8180-81b1-4642-be54-a8e9b4df354b does not have a summary. Skipping filtering.\n",
            "Node eba9414f-00cf-45cc-84b7-7be0beb16ffe does not have a summary. Skipping filtering.\n",
            "Node 736c393e-2387-4dd1-ad80-45bbd1b755b7 does not have a summary. Skipping filtering.\n",
            "Node a7fadb3d-52a9-4379-8f46-825449093350 does not have a summary. Skipping filtering.\n",
            "Node 165afaef-af6a-4f20-84fb-2cd1def3ceca does not have a summary. Skipping filtering.\n",
            "Node 51a6a98e-dbb6-4786-b75c-768eb9da4e6b does not have a summary. Skipping filtering.\n",
            "Node 64433efc-6981-466e-b341-2016781980f2 does not have a summary. Skipping filtering.\n",
            "Node e6a1956f-7c1f-44a4-a07d-cad46378216b does not have a summary. Skipping filtering.\n",
            "Node a5ddcdf0-dd8a-4e3a-9059-d7caf2951a90 does not have a summary. Skipping filtering.\n",
            "Node ba4bd3a1-cba0-4669-94a6-b1072f8e293b does not have a summary. Skipping filtering.\n",
            "Node 2e730e5d-5dad-4e81-9bd5-212b99f11bec does not have a summary. Skipping filtering.\n",
            "Node 7700e826-2224-47c0-995c-289bfaf4a57d does not have a summary. Skipping filtering.\n",
            "Node 7bd21940-e960-4883-80b6-31999949a23c does not have a summary. Skipping filtering.\n",
            "Node ce0e2972-141f-42a9-8240-8a2286cef0b2 does not have a summary. Skipping filtering.\n",
            "Node 09684d12-1c52-4e17-9a62-e89a64e5f6e2 does not have a summary. Skipping filtering.\n",
            "Node 1d2b52b2-068f-4772-8617-2819bed7ef3a does not have a summary. Skipping filtering.\n",
            "Node ac14191b-49a8-4e31-928e-498241cbf47e does not have a summary. Skipping filtering.\n",
            "Node e4e19956-a4e0-4f31-91f3-1a2aa2f70a20 does not have a summary. Skipping filtering.\n",
            "Node a99369a4-7cf5-4be8-b496-98587265472f does not have a summary. Skipping filtering.\n",
            "Node 44b4979f-83da-45b6-95ab-c3c4946b7c7a does not have a summary. Skipping filtering.\n",
            "Node ad0b1267-41cc-4fab-856c-25927eac6541 does not have a summary. Skipping filtering.\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "3aa0bcb3891c4218b990d7cdf229b785",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Applying [EmbeddingExtractor, ThemesExtractor, NERExtractor]:   0%|          | 0/220 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "f5633b4b3ed842b0a3ea4a89706e6d13",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Applying [CosineSimilarityBuilder, OverlapScoreBuilder]:   0%|          | 0/2 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "ae516658dc80480aa730b0447b2e22ed",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Generating personas:   0%|          | 0/3 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "fc5dacdc1cac4e1f9c5d64cf3caf1c86",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Generating Scenarios:   0%|          | 0/3 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "a53b2c7ea9ac450d8632373bf4a94dbc",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Generating Samples:   0%|          | 0/12 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>user_input</th>\n",
              "      <th>reference_contexts</th>\n",
              "      <th>reference</th>\n",
              "      <th>synthesizer_name</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Who is John Wick in the action movie?</td>\n",
              "      <td>[: 0\\nReview: The best way I can describe John...</td>\n",
              "      <td>John Wick is a character played by Keanu Reeve...</td>\n",
              "      <td>single_hop_specifc_query_synthesizer</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Why is John Wick so popular?</td>\n",
              "      <td>[: 2\\nReview: With the fourth installment scor...</td>\n",
              "      <td>The context indicates that the reviewer decide...</td>\n",
              "      <td>single_hop_specifc_query_synthesizer</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Who is Chad Stahelski and what is his role in ...</td>\n",
              "      <td>[: 3\\nReview: John wick has a very simple reve...</td>\n",
              "      <td>Chad Stahelski is the director of John Wick, a...</td>\n",
              "      <td>single_hop_specifc_query_synthesizer</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Who is John Wick?</td>\n",
              "      <td>[: 4\\nReview: Though he no longer has a taste ...</td>\n",
              "      <td>John Wick is a retired assassin and \"Boogeyman...</td>\n",
              "      <td>single_hop_specifc_query_synthesizer</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>How does the story complexity and character de...</td>\n",
              "      <td>[&lt;1-hop&gt;\\n\\n: 21\\nReview: Wow, this is one of ...</td>\n",
              "      <td>The first John Wick movie had a clear story, p...</td>\n",
              "      <td>multi_hop_abstract_query_synthesizer</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>john wick review how it like takin and john wi...</td>\n",
              "      <td>[&lt;1-hop&gt;\\n\\n: 9\\nReview: At first glance, John...</td>\n",
              "      <td>john wick review says it like takin and is a r...</td>\n",
              "      <td>multi_hop_abstract_query_synthesizer</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>How does the second John Wick movie show hardc...</td>\n",
              "      <td>[&lt;1-hop&gt;\\n\\n: 8\\nReview: In this 2nd installme...</td>\n",
              "      <td>The second John Wick movie features hardcore a...</td>\n",
              "      <td>multi_hop_abstract_query_synthesizer</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>How does the recognition of stunt talent in Jo...</td>\n",
              "      <td>[&lt;1-hop&gt;\\n\\n: 16\\nReview: John Wick 3 is witho...</td>\n",
              "      <td>In John Wick 3, the recognition of stunt talen...</td>\n",
              "      <td>multi_hop_abstract_query_synthesizer</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>how does the matrix relate to john wick and wh...</td>\n",
              "      <td>[&lt;1-hop&gt;\\n\\n: 7\\nReview: John Wick (2014) is t...</td>\n",
              "      <td>the context shows that john wick is directed b...</td>\n",
              "      <td>multi_hop_specific_query_synthesizer</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>Russian mobster kill dog and car and Wick reve...</td>\n",
              "      <td>[&lt;1-hop&gt;\\n\\n: 5\\nReview: Ultra-violent first e...</td>\n",
              "      <td>In the story, after Wick's dog is killed and h...</td>\n",
              "      <td>multi_hop_specific_query_synthesizer</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>John Wick 2 is like same old John Wick Chapter...</td>\n",
              "      <td>[&lt;1-hop&gt;\\n\\n: 10\\nReview: The first John Wick ...</td>\n",
              "      <td>Based on the context, John Wick 2 and John Wic...</td>\n",
              "      <td>multi_hop_specific_query_synthesizer</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>How does the international criminal brotherhoo...</td>\n",
              "      <td>[&lt;1-hop&gt;\\n\\n: 7\\nReview: John Wick (2014) is t...</td>\n",
              "      <td>In the context provided, The Marquis is portra...</td>\n",
              "      <td>multi_hop_specific_query_synthesizer</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                           user_input  \\\n",
              "0               Who is John Wick in the action movie?   \n",
              "1                        Why is John Wick so popular?   \n",
              "2   Who is Chad Stahelski and what is his role in ...   \n",
              "3                                   Who is John Wick?   \n",
              "4   How does the story complexity and character de...   \n",
              "5   john wick review how it like takin and john wi...   \n",
              "6   How does the second John Wick movie show hardc...   \n",
              "7   How does the recognition of stunt talent in Jo...   \n",
              "8   how does the matrix relate to john wick and wh...   \n",
              "9   Russian mobster kill dog and car and Wick reve...   \n",
              "10  John Wick 2 is like same old John Wick Chapter...   \n",
              "11  How does the international criminal brotherhoo...   \n",
              "\n",
              "                                   reference_contexts  \\\n",
              "0   [: 0\\nReview: The best way I can describe John...   \n",
              "1   [: 2\\nReview: With the fourth installment scor...   \n",
              "2   [: 3\\nReview: John wick has a very simple reve...   \n",
              "3   [: 4\\nReview: Though he no longer has a taste ...   \n",
              "4   [<1-hop>\\n\\n: 21\\nReview: Wow, this is one of ...   \n",
              "5   [<1-hop>\\n\\n: 9\\nReview: At first glance, John...   \n",
              "6   [<1-hop>\\n\\n: 8\\nReview: In this 2nd installme...   \n",
              "7   [<1-hop>\\n\\n: 16\\nReview: John Wick 3 is witho...   \n",
              "8   [<1-hop>\\n\\n: 7\\nReview: John Wick (2014) is t...   \n",
              "9   [<1-hop>\\n\\n: 5\\nReview: Ultra-violent first e...   \n",
              "10  [<1-hop>\\n\\n: 10\\nReview: The first John Wick ...   \n",
              "11  [<1-hop>\\n\\n: 7\\nReview: John Wick (2014) is t...   \n",
              "\n",
              "                                            reference  \\\n",
              "0   John Wick is a character played by Keanu Reeve...   \n",
              "1   The context indicates that the reviewer decide...   \n",
              "2   Chad Stahelski is the director of John Wick, a...   \n",
              "3   John Wick is a retired assassin and \"Boogeyman...   \n",
              "4   The first John Wick movie had a clear story, p...   \n",
              "5   john wick review says it like takin and is a r...   \n",
              "6   The second John Wick movie features hardcore a...   \n",
              "7   In John Wick 3, the recognition of stunt talen...   \n",
              "8   the context shows that john wick is directed b...   \n",
              "9   In the story, after Wick's dog is killed and h...   \n",
              "10  Based on the context, John Wick 2 and John Wic...   \n",
              "11  In the context provided, The Marquis is portra...   \n",
              "\n",
              "                        synthesizer_name  \n",
              "0   single_hop_specifc_query_synthesizer  \n",
              "1   single_hop_specifc_query_synthesizer  \n",
              "2   single_hop_specifc_query_synthesizer  \n",
              "3   single_hop_specifc_query_synthesizer  \n",
              "4   multi_hop_abstract_query_synthesizer  \n",
              "5   multi_hop_abstract_query_synthesizer  \n",
              "6   multi_hop_abstract_query_synthesizer  \n",
              "7   multi_hop_abstract_query_synthesizer  \n",
              "8   multi_hop_specific_query_synthesizer  \n",
              "9   multi_hop_specific_query_synthesizer  \n",
              "10  multi_hop_specific_query_synthesizer  \n",
              "11  multi_hop_specific_query_synthesizer  "
            ]
          },
          "execution_count": 67,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from ragas.testset import TestsetGenerator\n",
        "generator = TestsetGenerator(llm=generator_llm, embedding_model=generator_embeddings)\n",
        "dataset = generator.generate_with_langchain_docs(docs, testset_size=10)\n",
        "\n",
        "dataset.to_pandas()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 68,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Q: Who is John Wick in the action movie?\n",
            "GT: John Wick is a character played by Keanu Reeves who seeks revenge after someone takes something he loves, specifically his dog. The movie is known for its awesome action, stylish stunts, and kinetic chaos, with John Wick serving as a relatable hero.\n",
            "â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”\n",
            "Q: Why is John Wick so popular?\n",
            "GT: The context indicates that the reviewer decided to check out \"John Wick\" after the success of the previous films, which are apparently loved by everyone else in the world. This suggests that John Wick is popular due to its widespread acclaim and the appeal of its intense action and formidable characters.\n",
            "â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”\n",
            "Q: Who is Chad Stahelski and what is his role in the John Wick movie?\n",
            "GT: Chad Stahelski is the director of John Wick, and he is a stunt specialist whose expertise is evident in the film's virtuoso action sequences and well-made choreographies.\n",
            "â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”\n",
            "Q: Who is John Wick?\n",
            "GT: John Wick is a retired assassin and \"Boogeyman\" who has suffered a personal tragedy, leading him to seek vengeance after his dog and himself are attacked by Russian mobsters. He is portrayed as a formidable, indestructible character with a sardonic wit, involved in stylized, visceral action scenes.\n",
            "â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”\n",
            "Q: How does the story complexity and character development in the John Wick sequel compare to the original movie?\n",
            "GT: The first John Wick movie had a clear story, plot, and some character development, whereas the sequel is described as having more story complexity but less character development, with the reviewer noting it lacks the original's narrative depth and focusing more on action and violence.\n",
            "â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”\n",
            "Q: john wick review how it like takin and john wick good or bad\n",
            "GT: john wick review says it like takin and is a relentless, pulse-pounding thriller with intense action and good momentum, making it a very good action film overall.\n",
            "â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”\n",
            "Q: How does the second John Wick movie show hardcore action and gun shootings like in the first, but also more bloody and complex?\n",
            "GT: The second John Wick movie features hardcore action and gun shootings similar to the first film, with intense hand-to-hand combat and brutal killings. It also is more bloody and has more fighting, with increased complexity in the story, making it an even better version while maintaining the elements of hardcore action and gun shootings.\n",
            "â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”\n",
            "Q: How does the recognition of stunt talent in John Wick 3 contribute to the entertainment and excitement in movies, despite the lack of awards for such skills?\n",
            "GT: In John Wick 3, the recognition of stunt talent is evident through the extraordinary stunts performed by actors, such as throwing themselves from motorbikes and through glass, which significantly contribute to the entertainment and excitement of the film. The review highlights that the film's clear and impressive action sequences, driven by these talented stunt performers, make it a refreshing and joyful experience, even though such skills are not often acknowledged with awards like the Oscars.\n",
            "â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”\n",
            "Q: how does the matrix relate to john wick and why is it like the matrix in the movie john wick\n",
            "GT: the context shows that john wick is directed by reevess stuntman from the matrix and mentions that keanu reeves, who stars in john wick, is also known from the matrix, highlighting a connection between the two films and emphasizing the matrix's influence on john wick's action style and world-building.\n",
            "â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”\n",
            "Q: Russian mobster kill dog and car and Wick revenge, how he do that in Russia?\n",
            "GT: In the story, after Wick's dog is killed and his car stolen by a young Russian-American punk and his goons, Wick, who is a super-assassin, seeks revenge. The punk's father is a Russian mobster, and Wick's retaliation involves confronting the mobster and his gang, leading to a violent showdown. The context shows that Wick's actions are driven by the loss of his dog and car, and his background as a lethal assassin makes his revenge intense and deadly, especially in the Russian mob setting.\n",
            "â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”\n",
            "Q: John Wick 2 is like same old John Wick Chapter 2 with more violence but no new stuff, right?\n",
            "GT: Based on the context, John Wick 2 and John Wick Chapter 2 are both highly violent films featuring Keanu Reeves as the hitman. The review indicates that John Wick 2 doesn't surprise the reviewer and that John Wick Chapter 2 is just more of the same, with relentless violence and no new ground broken in action cinema. Therefore, they are similar in style and content, with no significant differences highlighted.\n",
            "â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”\n",
            "Q: How does the international criminal brotherhood known as The Marquis, as depicted in the context of John Wick's story, relate to the themes of The Matrix and the complex, formidable characters that define action films, and what does this connection reveal about the film's portrayal of revenge and power dynamics?\n",
            "GT: In the context provided, The Marquis is portrayed as part of the international criminal brotherhood that condemns John Wick, highlighting themes of revenge and formidable power. This connection aligns with the themes of The Matrix, which also features complex characters navigating a world of high-stakes conflict and layered allegiances. The portrayal of The Marquis as an antagonist who empowers criminal elements to deal with John Wick underscores the film's exploration of revenge and the intricate power dynamics within a criminal underworld, similar to the layered realities and formidable characters found in The Matrix. Together, these elements emphasize the film's focus on intense action, complex character motivations, and the relentless pursuit of retribution, making it a quintessential example of modern action cinema that combines visceral combat with intricate narrative themes.\n",
            "â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”\n"
          ]
        }
      ],
      "source": [
        "valid_samples = [s for s in dataset.samples if s.eval_sample.reference is not None]\n",
        "\n",
        "# print the testset (Question and Grounded Truth)\n",
        "for sample in dataset.samples:\n",
        "    print(\"Q:\", sample.eval_sample.user_input)\n",
        "    print(\"GT:\", sample.eval_sample.reference)\n",
        "    print(\"â€”\" * 60)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 69,
      "metadata": {},
      "outputs": [],
      "source": [
        "import time\n",
        "\n",
        "def safe_generate(llm, question, retries=3, delay=2):\n",
        "    for attempt in range(retries):\n",
        "        try:\n",
        "            result = llm.invoke(question)\n",
        "            return result.content if hasattr(result, \"content\") else str(result)\n",
        "        except Exception as e:\n",
        "            print(f\"âš ï¸ Retry {attempt+1} for generation failed: {e}\")\n",
        "            time.sleep(delay)\n",
        "    return \"Generation failed\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 70,
      "metadata": {},
      "outputs": [],
      "source": [
        "from datasets import Dataset\n",
        "from ragas import evaluate\n",
        "from ragas.metrics import (\n",
        "    answer_relevancy,\n",
        "    faithfulness,\n",
        "    context_recall,\n",
        "    context_precision,\n",
        "    answer_correctness,\n",
        ")\n",
        "\n",
        "\n",
        "def evaluate_per_sample(samples, retriever, llm, embeddings, name=\"naive\", sleep=3):\n",
        "    scores = {\n",
        "        \"answer_correctness\": [],\n",
        "        \"answer_relevancy\": [],\n",
        "        \"faithfulness\": [],\n",
        "        \"context_recall\": [],\n",
        "        \"context_precision\": [],\n",
        "    }\n",
        "\n",
        "    for i, sample in enumerate(samples, 1):\n",
        "        question = sample.eval_sample.user_input\n",
        "        ground_truth = sample.eval_sample.reference\n",
        "\n",
        "        docs = retriever.get_relevant_documents(question)\n",
        "        contexts = [doc.page_content for doc in docs]\n",
        "        \n",
        "        # Use safe LLM generation\n",
        "        answer = safe_generate(llm, question)\n",
        "        \n",
        "        eval_ds = Dataset.from_dict({\n",
        "            \"question\": [question],\n",
        "            \"contexts\": [contexts],\n",
        "            \"answer\": [answer],\n",
        "            \"ground_truth\": [ground_truth],\n",
        "        })\n",
        "\n",
        "        try:\n",
        "            result = evaluate(\n",
        "                dataset=eval_ds,\n",
        "                metrics=[\n",
        "                    answer_relevancy,\n",
        "                    faithfulness,\n",
        "                    context_recall,\n",
        "                    context_precision,\n",
        "                    answer_correctness,\n",
        "                ],\n",
        "                llm=llm,\n",
        "                embeddings=embeddings\n",
        "            )\n",
        "            for k in scores:\n",
        "                scores[k].append(result[k])\n",
        "            print(f\"[{name}] âœ… {i}/{len(samples)} complete\")\n",
        "        except Exception as e:\n",
        "            print(f\"[{name}] âŒ {i}/{len(samples)} failed: {e}\")\n",
        "            for k in scores:\n",
        "                scores[k].append(None)\n",
        "\n",
        "        time.sleep(sleep)  # â±ï¸ Control rate limit manually\n",
        "\n",
        "    return scores"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 71,
      "metadata": {},
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "def summarize_scores(scores_dict, name=\"Naive\"):\n",
        "    summary = {k: round(np.nanmean([v for v in values if v is not None]), 4)\n",
        "               for k, values in scores_dict.items()}\n",
        "    return pd.DataFrame([summary], index=[name])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 72,
      "metadata": {},
      "outputs": [],
      "source": [
        "retrievers = {\n",
        "    \"naive\": naive_retriever,\n",
        "    \"bm25\": bm25_retriever,\n",
        "    \"compression\": compression_retriever,\n",
        "    \"multi_query\": multi_query_retriever,\n",
        "    \"parent\": parent_document_retriever,\n",
        "    \"ensemble\": ensemble_retriever,\n",
        "    \"semantic\": semantic_retriever,\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 73,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "ðŸ” Evaluating retriever: naive\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\bsmith53\\AppData\\Local\\Temp\\ipykernel_6068\\4231787146.py:10: DeprecationWarning: callback_manager is deprecated. Please use callbacks instead.\n",
            "  llm=make_chat_model(retriever_name=retriever_name, model_name=\"gpt-4o\"),\n",
            "C:\\Users\\bsmith53\\AppData\\Local\\Temp\\ipykernel_6068\\2877002052.py:25: LangChainDeprecationWarning: The method `BaseRetriever.get_relevant_documents` was deprecated in langchain-core 0.1.46 and will be removed in 1.0. Use :meth:`~invoke` instead.\n",
            "  docs = retriever.get_relevant_documents(question)\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "54ad3da8ff9047b2ab77b088b88241aa",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Evaluating:   0%|          | 0/5 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[naive] âœ… 1/12 complete\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "d27d422ae402451cb7c6b16f7798bb0c",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Evaluating:   0%|          | 0/5 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[naive] âœ… 2/12 complete\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "aac631d5b4594e17be84481517c1edbc",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Evaluating:   0%|          | 0/5 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[naive] âœ… 3/12 complete\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "230ffcb42987432cbf6679effe374b6d",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Evaluating:   0%|          | 0/5 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[naive] âœ… 4/12 complete\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "a9c448b2385e4551a25597868f8c9bfe",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Evaluating:   0%|          | 0/5 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[naive] âœ… 5/12 complete\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "676cd31b777d441cb870e70ec27af6fb",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Evaluating:   0%|          | 0/5 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[naive] âœ… 6/12 complete\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "acc8cee7bd904e2aa0fd199299bccbb0",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Evaluating:   0%|          | 0/5 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[naive] âœ… 7/12 complete\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "2318c964e0574483aedefa75874a679e",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Evaluating:   0%|          | 0/5 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[naive] âœ… 8/12 complete\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "ed1fb49dc3d74d058df5324c9854978d",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Evaluating:   0%|          | 0/5 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[naive] âœ… 9/12 complete\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "be3dc13d29e94beab4ad1970c9a89c5a",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Evaluating:   0%|          | 0/5 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[naive] âœ… 10/12 complete\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "49fc7480080a4dba830967006cf51651",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Evaluating:   0%|          | 0/5 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[naive] âœ… 11/12 complete\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "dff55a2036b8442bb1834b53270a423a",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Evaluating:   0%|          | 0/5 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[naive] âœ… 12/12 complete\n",
            "\n",
            "ðŸ” Evaluating retriever: bm25\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\bsmith53\\AppData\\Local\\Temp\\ipykernel_6068\\4231787146.py:10: DeprecationWarning: callback_manager is deprecated. Please use callbacks instead.\n",
            "  llm=make_chat_model(retriever_name=retriever_name, model_name=\"gpt-4o\"),\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "9c75a0ffa2b7476f812cb3702b387233",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Evaluating:   0%|          | 0/5 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[bm25] âœ… 1/12 complete\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "4c7b5ec278fc4b1a9e7864c8fa87a450",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Evaluating:   0%|          | 0/5 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[bm25] âœ… 2/12 complete\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "a670f712cb9246fdac9026f5a422cff4",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Evaluating:   0%|          | 0/5 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[bm25] âœ… 3/12 complete\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "702b50c134ed4b64a6b575278cea9191",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Evaluating:   0%|          | 0/5 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[bm25] âœ… 4/12 complete\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "d4ed566672974b168d95901b11d7eaa2",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Evaluating:   0%|          | 0/5 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[bm25] âœ… 5/12 complete\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "912914b8ecbd4a1b965b676a56a92b68",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Evaluating:   0%|          | 0/5 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[bm25] âœ… 6/12 complete\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "583703e067d44266b662a42d63f2482c",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Evaluating:   0%|          | 0/5 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[bm25] âœ… 7/12 complete\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "496ca25fcca948c392f7391035378da2",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Evaluating:   0%|          | 0/5 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[bm25] âœ… 8/12 complete\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "bd927f5e5cef46f19deebc979aa73f5d",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Evaluating:   0%|          | 0/5 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[bm25] âœ… 9/12 complete\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "6710b1a4898e4724871504f7cf6f177d",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Evaluating:   0%|          | 0/5 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[bm25] âœ… 10/12 complete\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "3f68443cd5084697a9dff912dc9b54ae",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Evaluating:   0%|          | 0/5 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[bm25] âœ… 11/12 complete\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "09818162aee3466aa9f6a3dfaf7e9be6",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Evaluating:   0%|          | 0/5 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[bm25] âœ… 12/12 complete\n",
            "\n",
            "ðŸ” Evaluating retriever: compression\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\bsmith53\\AppData\\Local\\Temp\\ipykernel_6068\\4231787146.py:10: DeprecationWarning: callback_manager is deprecated. Please use callbacks instead.\n",
            "  llm=make_chat_model(retriever_name=retriever_name, model_name=\"gpt-4o\"),\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "0ea6208982844d91833a50f5f844f75c",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Evaluating:   0%|          | 0/5 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[compression] âœ… 1/12 complete\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "8e4a755414714dbfb955adbf5e3cd20a",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Evaluating:   0%|          | 0/5 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[compression] âœ… 2/12 complete\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "606dd9944877415b9ab1cb088391b59a",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Evaluating:   0%|          | 0/5 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[compression] âœ… 3/12 complete\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "8e3f7725fd8e45b1b4cb0c24a630d886",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Evaluating:   0%|          | 0/5 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[compression] âœ… 4/12 complete\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "38069968e50d4966a5c9115527140e44",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Evaluating:   0%|          | 0/5 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[compression] âœ… 5/12 complete\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "6664a2bf66274192b6e625f1a11906c5",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Evaluating:   0%|          | 0/5 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[compression] âœ… 6/12 complete\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "af61e1a905f44811b9a9e8ebf7f9390d",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Evaluating:   0%|          | 0/5 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[compression] âœ… 7/12 complete\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "d629d8d8a6b543e4984689bcf21bfddc",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Evaluating:   0%|          | 0/5 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[compression] âœ… 8/12 complete\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "2389baf2fbfb4a70891ed1dcbec92a59",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Evaluating:   0%|          | 0/5 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[compression] âœ… 9/12 complete\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "da8fd51ae1354e67a14a1dc6a84a9f57",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Evaluating:   0%|          | 0/5 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[compression] âœ… 10/12 complete\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "1eaf0735a2c54507836388c8276a1f06",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Evaluating:   0%|          | 0/5 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[compression] âœ… 11/12 complete\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "748d543f1cd04f27bd48c641780f1d69",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Evaluating:   0%|          | 0/5 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[compression] âœ… 12/12 complete\n",
            "\n",
            "ðŸ” Evaluating retriever: multi_query\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\bsmith53\\AppData\\Local\\Temp\\ipykernel_6068\\4231787146.py:10: DeprecationWarning: callback_manager is deprecated. Please use callbacks instead.\n",
            "  llm=make_chat_model(retriever_name=retriever_name, model_name=\"gpt-4o\"),\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "5ae1e5648e184224ac200ab5a0a1df82",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Evaluating:   0%|          | 0/5 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[multi_query] âœ… 1/12 complete\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "8baf38674dcf49f293da50ddf8abbc5b",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Evaluating:   0%|          | 0/5 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[multi_query] âœ… 2/12 complete\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "f59e3e1ec2b24d2a8303febe14060908",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Evaluating:   0%|          | 0/5 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[multi_query] âœ… 3/12 complete\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "3bdfb2cb3ac84c9bbf8f070c4a4936ec",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Evaluating:   0%|          | 0/5 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[multi_query] âœ… 4/12 complete\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "08525c825fdc48278505637334d896ec",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Evaluating:   0%|          | 0/5 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[multi_query] âœ… 5/12 complete\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "abf5a324f6724e458fb3d757f4fca259",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Evaluating:   0%|          | 0/5 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[multi_query] âœ… 6/12 complete\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "6c63dd88656d48babce8a6605a18d1e4",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Evaluating:   0%|          | 0/5 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[multi_query] âœ… 7/12 complete\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "f130e7aabae1477da8aef0e04b1dcd40",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Evaluating:   0%|          | 0/5 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[multi_query] âœ… 8/12 complete\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "1421bc362acd4db4b96ab345bd961f29",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Evaluating:   0%|          | 0/5 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[multi_query] âœ… 9/12 complete\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "d744ae2c8342440d9d8406ee2f143fb3",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Evaluating:   0%|          | 0/5 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[multi_query] âœ… 10/12 complete\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "bd9ba09959054da3a3ac2877fc529d81",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Evaluating:   0%|          | 0/5 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[multi_query] âœ… 11/12 complete\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "5c7d4cdbcec446979aebee0024870633",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Evaluating:   0%|          | 0/5 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[multi_query] âœ… 12/12 complete\n",
            "\n",
            "ðŸ” Evaluating retriever: parent\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\bsmith53\\AppData\\Local\\Temp\\ipykernel_6068\\4231787146.py:10: DeprecationWarning: callback_manager is deprecated. Please use callbacks instead.\n",
            "  llm=make_chat_model(retriever_name=retriever_name, model_name=\"gpt-4o\"),\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "0f9c3a276a7840c6b4eb213458aa38e5",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Evaluating:   0%|          | 0/5 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[parent] âœ… 1/12 complete\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "1ad54bb31804417d9975cc13b990ee14",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Evaluating:   0%|          | 0/5 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[parent] âœ… 2/12 complete\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "f8ac7dc40ea44b39b525b2b38ddb35b4",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Evaluating:   0%|          | 0/5 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[parent] âœ… 3/12 complete\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "eba9477d06ea41eb941d7e788cbaa1a0",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Evaluating:   0%|          | 0/5 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[parent] âœ… 4/12 complete\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "7af73245982645e4a4e7edc444fc47c6",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Evaluating:   0%|          | 0/5 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[parent] âœ… 5/12 complete\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "cc9819bb91b742139aabe4a7f50feadd",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Evaluating:   0%|          | 0/5 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[parent] âœ… 6/12 complete\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "88a1691d39754915beeb82480d2103c1",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Evaluating:   0%|          | 0/5 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[parent] âœ… 7/12 complete\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "92d25e7d786747d88c31065ba2fb80ee",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Evaluating:   0%|          | 0/5 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[parent] âœ… 8/12 complete\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "20c1df40329a480f9c1e27ad658040a3",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Evaluating:   0%|          | 0/5 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[parent] âœ… 9/12 complete\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "d6ac852a1ddd4ad091e09ebe5d420169",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Evaluating:   0%|          | 0/5 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[parent] âœ… 10/12 complete\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "00fc17cc0c2749c8a8cf210f9bbcc85a",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Evaluating:   0%|          | 0/5 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[parent] âœ… 11/12 complete\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "bad0ddce2dc541788eae64e358576f93",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Evaluating:   0%|          | 0/5 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[parent] âœ… 12/12 complete\n",
            "\n",
            "ðŸ” Evaluating retriever: ensemble\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\bsmith53\\AppData\\Local\\Temp\\ipykernel_6068\\4231787146.py:10: DeprecationWarning: callback_manager is deprecated. Please use callbacks instead.\n",
            "  llm=make_chat_model(retriever_name=retriever_name, model_name=\"gpt-4o\"),\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "5e92ca66c402486fb98fc10264dd381c",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Evaluating:   0%|          | 0/5 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[ensemble] âœ… 1/12 complete\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "3a0bbfbe44034d25a3aa5448ca7c9d8f",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Evaluating:   0%|          | 0/5 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[ensemble] âœ… 2/12 complete\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "89b5d1a601f3464fa9e0e799d1be547a",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Evaluating:   0%|          | 0/5 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[ensemble] âœ… 3/12 complete\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "c65daa8b6bb34c3e8d87586b81767a2c",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Evaluating:   0%|          | 0/5 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[ensemble] âœ… 4/12 complete\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "2dff40b1aa0c450b81ad730d0bfc8eef",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Evaluating:   0%|          | 0/5 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[ensemble] âœ… 5/12 complete\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "7749e7afb0e84ababcc200f491dd339d",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Evaluating:   0%|          | 0/5 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[ensemble] âœ… 6/12 complete\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "3b85a00ccfa54edc92ab647e899d55ca",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Evaluating:   0%|          | 0/5 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[ensemble] âœ… 7/12 complete\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "68ef81166f254c84b408f05133292333",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Evaluating:   0%|          | 0/5 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[ensemble] âœ… 8/12 complete\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "1593fffadac646ca8def623829e9a9d4",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Evaluating:   0%|          | 0/5 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[ensemble] âœ… 9/12 complete\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "a9ee4c3ce845420ab0b1c0aa8e725f1d",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Evaluating:   0%|          | 0/5 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[ensemble] âœ… 10/12 complete\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "657a896408494c48891821aeb6447bbd",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Evaluating:   0%|          | 0/5 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[ensemble] âœ… 11/12 complete\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "1af48b106ba7490885c49b7c8dd78ccc",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Evaluating:   0%|          | 0/5 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[ensemble] âœ… 12/12 complete\n",
            "\n",
            "ðŸ” Evaluating retriever: semantic\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\bsmith53\\AppData\\Local\\Temp\\ipykernel_6068\\4231787146.py:10: DeprecationWarning: callback_manager is deprecated. Please use callbacks instead.\n",
            "  llm=make_chat_model(retriever_name=retriever_name, model_name=\"gpt-4o\"),\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "502e9ae8d4f844c39a3bfcb6f18dec86",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Evaluating:   0%|          | 0/5 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[semantic] âœ… 1/12 complete\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "25bb0294255748ae8c2537b6564ca7f7",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Evaluating:   0%|          | 0/5 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[semantic] âœ… 2/12 complete\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "dc05c364acc042a1b20ced8b69d21208",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Evaluating:   0%|          | 0/5 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[semantic] âœ… 3/12 complete\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "874432cc894d448796f630a99616adf2",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Evaluating:   0%|          | 0/5 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[semantic] âœ… 4/12 complete\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "9fd0fd8bacf44887b7138830fdb706a6",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Evaluating:   0%|          | 0/5 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[semantic] âœ… 5/12 complete\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "acc66fbaf4a84506bc42072d55d07559",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Evaluating:   0%|          | 0/5 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[semantic] âœ… 6/12 complete\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "1666d020e33f4040909f8a12c3269432",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Evaluating:   0%|          | 0/5 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[semantic] âœ… 7/12 complete\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "9933a4dd285f4ffba8d9a893f680aedb",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Evaluating:   0%|          | 0/5 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[semantic] âœ… 8/12 complete\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "78aca05515be4463aa8b826fa8c11160",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Evaluating:   0%|          | 0/5 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[semantic] âœ… 9/12 complete\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "ebd943e6f74b408ca21da131b9bb02c5",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Evaluating:   0%|          | 0/5 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[semantic] âœ… 10/12 complete\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "0036119ce8f2456e83a0d3e161f6d6f9",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Evaluating:   0%|          | 0/5 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[semantic] âœ… 11/12 complete\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "f1e0578a62104a4ab8ff7cf54673d3d6",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Evaluating:   0%|          | 0/5 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[semantic] âœ… 12/12 complete\n"
          ]
        }
      ],
      "source": [
        "all_scores = {}\n",
        "all_dataframes = []\n",
        "\n",
        "for retriever_name, retriever in retrievers.items():\n",
        "    print(f\"\\nðŸ” Evaluating retriever: {retriever_name}\")\n",
        "\n",
        "    scores = evaluate_per_sample(\n",
        "        samples=valid_samples,\n",
        "        retriever=retriever,\n",
        "        llm=make_chat_model(retriever_name=retriever_name, model_name=\"gpt-4o\"),\n",
        "        embeddings=embeddings,\n",
        "        name=retriever_name,\n",
        "        sleep=4\n",
        "    )\n",
        "\n",
        "    # Store scores and summarized DataFrame\n",
        "    all_scores[retriever_name] = scores\n",
        "    df = summarize_scores(scores, name=retriever_name.capitalize())\n",
        "    all_dataframes.append(df)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 74,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "             answer_correctness  answer_relevancy  faithfulness  \\\n",
            "Naive                    0.4349            0.8002        0.6103   \n",
            "Bm25                     0.4071            0.8162        0.3214   \n",
            "Compression              0.3975            0.8053        0.3559   \n",
            "Multi_query              0.4098            0.8083        0.6259   \n",
            "Parent                   0.3851            0.8120        0.2566   \n",
            "Ensemble                 0.3989            0.8071        0.5786   \n",
            "Semantic                 0.4217            0.8097        0.5222   \n",
            "\n",
            "             context_recall  context_precision  \n",
            "Naive                0.7917             0.7654  \n",
            "Bm25                 0.5069             0.4977  \n",
            "Compression          0.7500             0.8611  \n",
            "Multi_query          0.7917             0.7654  \n",
            "Parent               0.5764             0.5903  \n",
            "Ensemble             0.8333             0.6121  \n",
            "Semantic             0.8333             0.6364  \n"
          ]
        }
      ],
      "source": [
        "final_df = pd.concat(all_dataframes, axis=0)\n",
        "\n",
        "print(final_df)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 75,
      "metadata": {},
      "outputs": [],
      "source": [
        "from langsmith import Client\n",
        "\n",
        "def get_langsmith_metrics(project_name, model_name=\"gpt-4o\"):\n",
        "    client = Client()\n",
        "    runs = list(client.list_runs(project_name=project_name, run_type=\"llm\"))\n",
        "\n",
        "    latencies = []\n",
        "    costs = []\n",
        "\n",
        "    for run in runs:\n",
        "        full_run = client.read_run(run.id)\n",
        "\n",
        "        if full_run.start_time and full_run.end_time:\n",
        "            duration = (full_run.end_time - full_run.start_time).total_seconds()\n",
        "            latencies.append(duration)\n",
        "\n",
        "        usage = (\n",
        "            full_run.outputs\n",
        "            .get(\"llm_output\", {})\n",
        "            .get(\"token_usage\", {})\n",
        "        )\n",
        "\n",
        "        input_tokens = usage.get(\"prompt_tokens\", 0)\n",
        "        output_tokens = usage.get(\"completion_tokens\", 0)\n",
        "\n",
        "        if \"gpt-4o\" in model_name:\n",
        "            cost = (input_tokens / 1000) * 0.005 + (output_tokens / 1000) * 0.015\n",
        "        elif \"gpt-3.5\" in model_name:\n",
        "            cost = (input_tokens / 1000) * 0.0015 + (output_tokens / 1000) * 0.002\n",
        "        else:\n",
        "            cost = 0\n",
        "\n",
        "        costs.append(cost)\n",
        "\n",
        "    avg_latency = round(sum(latencies) / len(latencies), 3) if latencies else None\n",
        "    total_cost = round(sum(costs), 4) if costs else None\n",
        "\n",
        "    return avg_latency, total_cost"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 76,
      "metadata": {},
      "outputs": [],
      "source": [
        "#client = Client()\n",
        "#print(client.get_projects())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 77,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processing tracing information for ragas-eval-naive\n",
            "Processing tracing information for ragas-eval-bm25\n",
            "Processing tracing information for ragas-eval-compression\n",
            "Processing tracing information for ragas-eval-multi_query\n",
            "Processing tracing information for ragas-eval-parent\n",
            "Processing tracing information for ragas-eval-ensemble\n",
            "Processing tracing information for ragas-eval-semantic\n"
          ]
        }
      ],
      "source": [
        "latencies = []\n",
        "costs = []\n",
        "\n",
        "\n",
        "\n",
        "for name in retrievers.keys():\n",
        "    project_name = f\"ragas-eval-{name}\"\n",
        "    print(\"Processing tracing information for\", project_name)\n",
        "    latency, cost = get_langsmith_metrics(project_name)\n",
        "    latencies.append(latency)\n",
        "    costs.append(cost)\n",
        "\n",
        "final_df[\"avg_latency_s\"] = latencies\n",
        "final_df[\"total_cost_usd\"] = costs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 78,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Latency Values:  [7.014, 7.978, 8.277, 8.395, 8.387, 7.046, 7.595]\n",
            "Cost Values:  [0.055, 0.0573, 0.0576, 0.0583, 0.0629, 0.0604, 0.0543]\n",
            "             answer_correctness  answer_relevancy  faithfulness  \\\n",
            "Naive                    0.4349            0.8002        0.6103   \n",
            "Bm25                     0.4071            0.8162        0.3214   \n",
            "Compression              0.3975            0.8053        0.3559   \n",
            "Multi_query              0.4098            0.8083        0.6259   \n",
            "Parent                   0.3851            0.8120        0.2566   \n",
            "Ensemble                 0.3989            0.8071        0.5786   \n",
            "Semantic                 0.4217            0.8097        0.5222   \n",
            "\n",
            "             context_recall  context_precision  avg_latency_s  total_cost_usd  \n",
            "Naive                0.7917             0.7654          7.014          0.0550  \n",
            "Bm25                 0.5069             0.4977          7.978          0.0573  \n",
            "Compression          0.7500             0.8611          8.277          0.0576  \n",
            "Multi_query          0.7917             0.7654          8.395          0.0583  \n",
            "Parent               0.5764             0.5903          8.387          0.0629  \n",
            "Ensemble             0.8333             0.6121          7.046          0.0604  \n",
            "Semantic             0.8333             0.6364          7.595          0.0543  \n"
          ]
        }
      ],
      "source": [
        "print(\"Latency Values: \", latencies)\n",
        "print(\"Cost Values: \", costs)\n",
        "\n",
        "print(final_df)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 80,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+--------------------+-----------+---------+--------+---------------+---------------+----------+------------+------------+\n",
            "|                    | Group     |   Naive |   Bm25 |   Compression |   Multi_query |   Parent |   Ensemble |   Semantic |\n",
            "+====================+===========+=========+========+===============+===============+==========+============+============+\n",
            "| context_precision  | Retriever |  0.7654 | 0.4977 |        0.8611 |        0.7654 |   0.5903 |     0.6121 |     0.6364 |\n",
            "+--------------------+-----------+---------+--------+---------------+---------------+----------+------------+------------+\n",
            "| context_recall     | Retriever |  0.7917 | 0.5069 |        0.75   |        0.7917 |   0.5764 |     0.8333 |     0.8333 |\n",
            "+--------------------+-----------+---------+--------+---------------+---------------+----------+------------+------------+\n",
            "| faithfulness       | Retriever |  0.6103 | 0.3214 |        0.3559 |        0.6259 |   0.2566 |     0.5786 |     0.5222 |\n",
            "+--------------------+-----------+---------+--------+---------------+---------------+----------+------------+------------+\n",
            "| answer_relevancy   | Answer    |  0.8002 | 0.8162 |        0.8053 |        0.8083 |   0.812  |     0.8071 |     0.8097 |\n",
            "+--------------------+-----------+---------+--------+---------------+---------------+----------+------------+------------+\n",
            "| answer_correctness | Answer    |  0.4349 | 0.4071 |        0.3975 |        0.4098 |   0.3851 |     0.3989 |     0.4217 |\n",
            "+--------------------+-----------+---------+--------+---------------+---------------+----------+------------+------------+\n",
            "| avg_latency_s      | Infra     |  7.014  | 7.978  |        8.277  |        8.395  |   8.387  |     7.046  |     7.595  |\n",
            "+--------------------+-----------+---------+--------+---------------+---------------+----------+------------+------------+\n",
            "| total_cost_usd     | Infra     |  0.055  | 0.0573 |        0.0576 |        0.0583 |   0.0629 |     0.0604 |     0.0543 |\n",
            "+--------------------+-----------+---------+--------+---------------+---------------+----------+------------+------------+\n"
          ]
        }
      ],
      "source": [
        "from tabulate import tabulate\n",
        "\n",
        "# switch the columns and the rows so that the metrics are the rows and the retrievers are the columns.\n",
        "final_df = final_df.T\n",
        "\n",
        "# Define groups\n",
        "retriever_metrics = [\"context_precision\", \"context_recall\", \"faithfulness\"]\n",
        "answer_metrics = [\"answer_relevancy\", \"answer_correctness\"]\n",
        "infra_metrics = [\"avg_latency_s\", \"total_cost_usd\"]\n",
        "\n",
        "# Reorder with blank rows as visual separators\n",
        "ordered_rows = (\n",
        "    retriever_metrics +\n",
        "    answer_metrics +\n",
        "    infra_metrics\n",
        ")\n",
        "\n",
        "# Reindex with visual grouping\n",
        "df_grouped = final_df.reindex(ordered_rows)\n",
        "\n",
        "# Add a \"Group\" column for display/printing\n",
        "group_labels = {\n",
        "    \"context_precision\": \"Retriever\",\n",
        "    \"context_recall\": \"Retriever\",\n",
        "    \"faithfulness\": \"Retriever\",\n",
        "    \"answer_relevancy\": \"Answer\",\n",
        "    \"answer_correctness\": \"Answer\",\n",
        "    \"avg_latency_s\": \"Infra\",\n",
        "    \"total_cost_usd\": \"Infra\",\n",
        "}\n",
        "\n",
        "df_grouped.insert(0, \"Group\", [group_labels.get(m, \"\") for m in df_grouped.index])\n",
        "\n",
        "\n",
        "print(tabulate(df_grouped, headers=\"keys\", tablefmt=\"grid\"))"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.2"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
